{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import pickle as pkl\n",
    "from datasets import Dataset\n",
    "from random import uniform\n",
    "from time import sleep"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Getting all the links of the pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_page = 4150\n",
    "link_list = []\n",
    "for i in range(1, last_page+1):\n",
    "    link_list.append(\"https://stats.stackexchange.com/questions?tab=votes&page={}\".format(i))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Getting all the links of the questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "questions = []\n",
    "start = 0\n",
    "end = 500\n",
    "for link in tqdm(link_list[start:end]):\n",
    "    page = requests.get(link)\n",
    "    if page.status_code == 200:\n",
    "        pageParsed = BeautifulSoup(page.content, 'html.parser')\n",
    "        try:\n",
    "            all_page = pageParsed.find_all('div', {'class':'s-post-summary--content'})\n",
    "            for question in all_page:\n",
    "                question_link = question.find('h3', class_='s-post-summary--content-title').find('a')['href']\n",
    "                questions.append('https://stats.stackexchange.com' + question_link)\n",
    "        except:\n",
    "            print('Failed')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save the links list of the questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('questions_links.pkl', 'wb') as file:\n",
    "    pkl.dump(questions, file)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Open the list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25000\n"
     ]
    }
   ],
   "source": [
    "with open('questions_links.pkl', 'rb') as file:\n",
    "    questions_links = pkl.load(file)\n",
    "print(len(questions_links))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create a dictionary that contains:\n",
    "\n",
    "- index\n",
    "\n",
    "- question\n",
    "\n",
    "- answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "How to choose the number of hidden layers and nodes in a feedforward neural network?\n"
     ]
    }
   ],
   "source": [
    "question_link = \"https://stats.stackexchange.com/questions/181/how-to-choose-the-number-of-hidden-layers-and-nodes-in-a-feedforward-neural-netw\"\n",
    "page = requests.get(question_link)\n",
    "pageParsed = BeautifulSoup(page.content, 'html.parser')\n",
    "print(pageParsed.find('div', {'class': 'd-flex sm:fd-column'}).find('a').text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape(df_dict, idx, start, stop, save=True):\n",
    "    \n",
    "    # Set headers and user agent\n",
    "    headers = {'User-Agent': \n",
    "        'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/88.0.4324.150 Safari/537.36'}\n",
    "    page_num = start\n",
    "    for question_link in tqdm(questions_links[start:stop]):\n",
    "        sleep(uniform(0.5, 1.0))\n",
    "\n",
    "        try:\n",
    "            page = requests.get(question_link, headers=headers)\n",
    "            pageParsed = BeautifulSoup(page.content, 'html.parser')\n",
    "\n",
    "            question = pageParsed.find('div', {'class': 'd-flex sm:fd-column'}).find('a').text\n",
    "            texts = pageParsed.find_all('div', {'class': 's-prose js-post-body'})\n",
    "\n",
    "            if len(texts) > 1:\n",
    "                #question = texts[0].text.strip()\n",
    "\n",
    "                for answer in texts[1:]:\n",
    "                    df_dict[idx] = {'question': question, 'answer': answer.text.strip()}\n",
    "                    idx += 1\n",
    "        except:\n",
    "            print(f'Failed page: {page_num}')\n",
    "            \n",
    "        page_num += page_num\n",
    "\n",
    "    if save == True:\n",
    "        with open('df_dict.pkl', 'wb') as file:\n",
    "            pkl.dump(df_dict, file)\n",
    "            \n",
    "    return df_dict, idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [5:42:31<00:00,  2.06s/it]  \n"
     ]
    }
   ],
   "source": [
    "df_dict = {}\n",
    "idx = 1\n",
    "start = 0\n",
    "stop = 10000\n",
    "df_dict, idx = scrape(df_dict=df_dict, idx=idx, start=start, stop=stop, save=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape2(df_dict, idx, start, stop, save=True):\n",
    "    \n",
    "    # Set headers and user agent\n",
    "    headers = {'User-Agent': \n",
    "        'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/88.0.4324.150 Safari/537.36'}\n",
    "    page_num = start\n",
    "    for question_link in tqdm(questions_links[start:stop]):\n",
    "        sleep(uniform(0.4, 0.6))\n",
    "\n",
    "        try:\n",
    "            page = requests.get(question_link, headers=headers)\n",
    "            pageParsed = BeautifulSoup(page.content, 'html.parser')\n",
    "\n",
    "            question = pageParsed.find('div', {'class': 'd-flex sm:fd-column'}).find('a').text\n",
    "            texts = pageParsed.find_all('div', {'class': 's-prose js-post-body'})\n",
    "\n",
    "            if len(texts) > 1:\n",
    "                #question = texts[0].text.strip()\n",
    "\n",
    "                for answer in texts[1:]:\n",
    "                    df_dict[idx] = {'question': question, 'answer': answer.text.strip()}\n",
    "                    idx += 1\n",
    "        except:\n",
    "            print(f'Failed page: {page_num}')\n",
    "            \n",
    "        page_num += page_num\n",
    "\n",
    "    if save == True:\n",
    "        with open('df_dict2.pkl', 'wb') as file:\n",
    "            pkl.dump(df_dict, file)\n",
    "            \n",
    "    return df_dict, idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 1048/15000 [18:06<3:42:37,  1.04it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed page: 15080143012651102122105311357894339192625630629371264454491537662404055861234318233427433945345664359270563562536002092912033851249947657947764798994417377555483387729269740087126710097647697950991970872765238960725218615191034428672351193103876676882863794007328060981060073868574984560324723087895364035912432353280000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 1049/15000 [18:07<3:24:00,  1.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed page: 30160286025302204244210622715788678385251261258742528908983075324808111722468636466854867890691328718541127125072004185824067702499895315895529597988834755110966775458539480174253420195295395901983941745530477921450437230382068857344702386207753353765727588014656121962120147737149969120649446175790728071824864706560000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 1050/15000 [18:07<3:13:28,  1.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed page: 60320572050604408488421245431577356770502522517485057817966150649616223444937272933709735781382657437082254250144008371648135404999790631791059195977669510221933550917078960348506840390590791803967883491060955842900874460764137714689404772415506707531455176029312243924240295474299938241298892351581456143649729413120000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15000/15000 [4:22:57<00:00,  1.05s/it]   \n"
     ]
    }
   ],
   "source": [
    "df_dict2 = {}\n",
    "idx = 100000\n",
    "start = 10000\n",
    "stop = 25000\n",
    "df_dict2, idx = scrape2(df_dict=df_dict2, idx=idx, start=start, stop=stop, save=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create a dataframe and then a transformers Dataset from the dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(623, 4)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>idx</th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "      <th>conversation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>In today's pattern recognition class my profes...</td>\n",
       "      <td>Imagine a big family dinner where everybody st...</td>\n",
       "      <td>In today's pattern recognition class my profes...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>In today's pattern recognition class my profes...</td>\n",
       "      <td>The manuscript \"A tutorial on Principal Compon...</td>\n",
       "      <td>In today's pattern recognition class my profes...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>In today's pattern recognition class my profes...</td>\n",
       "      <td>Let's do (2) first.  PCA fits an ellipsoid to ...</td>\n",
       "      <td>In today's pattern recognition class my profes...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>In today's pattern recognition class my profes...</td>\n",
       "      <td>Hmm, here goes for a completely non-mathematic...</td>\n",
       "      <td>In today's pattern recognition class my profes...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>In today's pattern recognition class my profes...</td>\n",
       "      <td>I'd answer in \"layman's terms\" by saying that ...</td>\n",
       "      <td>In today's pattern recognition class my profes...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   idx                                           question   \n",
       "0    1  In today's pattern recognition class my profes...  \\\n",
       "1    2  In today's pattern recognition class my profes...   \n",
       "2    3  In today's pattern recognition class my profes...   \n",
       "3    4  In today's pattern recognition class my profes...   \n",
       "4    5  In today's pattern recognition class my profes...   \n",
       "\n",
       "                                              answer   \n",
       "0  Imagine a big family dinner where everybody st...  \\\n",
       "1  The manuscript \"A tutorial on Principal Compon...   \n",
       "2  Let's do (2) first.  PCA fits an ellipsoid to ...   \n",
       "3  Hmm, here goes for a completely non-mathematic...   \n",
       "4  I'd answer in \"layman's terms\" by saying that ...   \n",
       "\n",
       "                                        conversation  \n",
       "0  In today's pattern recognition class my profes...  \n",
       "1  In today's pattern recognition class my profes...  \n",
       "2  In today's pattern recognition class my profes...  \n",
       "3  In today's pattern recognition class my profes...  \n",
       "4  In today's pattern recognition class my profes...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "rows = [{'idx': key, 'question': value['question'], 'answer': value['answer']} for key, value in df_dict.items()]\n",
    "df = pd.DataFrame(rows)\n",
    "df['conversation'] = df['question'] + '\\n\\n' + df['answer']\n",
    "print(df.shape)\n",
    "display(df.head())\n",
    "dataset = Dataset.from_pandas(df)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('df_dict.pkl', 'wb') as file:\n",
    "    pkl.dump(df_dict, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('dataset.pkl', 'wb') as file:\n",
    "    pkl.dump(dataset, file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
