predictions <- predict(modello_forest, newdata = Dn_2)
table(predictions)
cm = table(predictions,Dn_2$y)
classification_err <- 1 - sum(diag(cm)) / sum(cm)
classification_err
set.seed(123)
N <- nrow(train)
n1 <- 0.7*N
idx <- sample(1:N, n1, replace=F)
N <- nrow(train)
n1 <- 0.7*N
idx <- sample(1:N, n1, replace=F)
```{r }
Dn_1 <- train_new[idx, ]
Dn_2 <- train_new[-idx, ]
library(randomForest)
modello_forest <- randomForest(factor(y) ~ . -id, data = Dn_1)
summary(modello_forest)
predictions <- predict(modello_forest, newdata = Dn_2)
table(predictions)
table(Dn_2$y)
table(predictions)
cm = table(predictions,Dn_2$y)
classification_err <- 1 - sum(diag(cm)) / sum(cm)
classification_err
n1 <- 0.5*N
idx <- sample(1:N, n1, replace=F)
Dn_1 <- train_new[idx, ]
Dn_2 <- train_new[-idx, ]
model = glm(factor(y) ~ . -id, family = binomial(link = "logit"), data = Dn_1)
modello_forest <- randomForest(factor(y) ~ . -id, data = Dn_1)
modello_forest <- randomForest(factor(y) ~ . -id, data = Dn_1)
summary(modello_forest)
predictions <- predict(modello_forest, newdata = Dn_2)
predictions <- predict(modello_forest, newdata = Dn_2)
table(predictions)
table(Dn_2$y)
table(predictions)
table(predictions)
table(Dn_2$y)
table(predictions)
cm = table(predictions,Dn_2$y)
classification_err <- 1 - sum(diag(cm)) / sum(cm)
classification_err
set.seed(123)
N <- nrow(train)
n1 <- 0.7*N
idx <- sample(1:N, n1, replace=F)
Dn_1 <- train_new[idx, ]
Dn_2 <- train_new[-idx, ]
library(randomForest)
modello_forest <- randomForest(factor(y) ~ . -id, data = Dn_1)
summary(modello_forest)
predictions <- predict(modello_forest, newdata = Dn_2)
table(predictions)
table(Dn_2$y)
table(predictions)
cm = table(predictions,Dn_2$y)
classification_err <- 1 - sum(diag(cm)) / sum(cm)
classification_err
set.seed(123)
N <- nrow(train)
n1 <- 0.7*N
idx <- sample(1:N, n1, replace=F)
Dn_1 <- train_new[idx, ]
Dn_2 <- train_new[-idx, ]
model = glm(factor(y) ~ . -id, family = binomial(link = "logit"), data = Dn_1)
summary(model)
predicts <- predict(model, newdata = Dn_2, type = "response")
binary_predictions <- ifelse(predicts >= 0.5, 1, 0)
model$y
cm = table(binary_predictions,Dn_2$y)
cm
classification_err <- 1 - sum(diag(cm)) / sum(cm)
classification_err
library(randomForest)
modello_forest <- randomForest(factor(y) ~ . -id, data = Dn_1)
summary(modello_forest)
predictions <- predict(modello_forest, newdata = Dn_2)
table(predictions)
table(Dn_2$y)
table(predictions)
cm = table(predictions,Dn_2$y)
classification_err <- 1 - sum(diag(cm)) / sum(cm)
classification_err
library(randomForest)
modello_forest <- randomForest(factor(y) ~ . -id, data = Dn_1)
#summary(modello_forest)
predictions <- predict(modello_forest, newdata = Dn_2)
table(predictions)
table(Dn_2$y)
cm = table(predictions,Dn_2$y)
classification_err <- 1 - sum(diag(cm)) / sum(cm)
classification_err
set.seed(123)
N <- nrow(train)
n1 <- 0.7*N
idx <- sample(1:N, n1, replace=F)
Dn_1 <- train_new[idx, ]
Dn_2 <- train_new[-idx, ]
library(randomForest)
modello_forest <- randomForest(factor(y) ~ . -id, data = Dn_1)
#summary(modello_forest)
predictions <- predict(modello_forest, newdata = Dn_2)
table(predictions)
table(Dn_2$y)
cm = table(predictions,Dn_2$y)
classification_err <- 1 - sum(diag(cm)) / sum(cm)
classification_err
modello_forest <- randomForest(factor(y) ~ . -id, data = Dn_1, importance = TRUE)
predictions <- predict(modello_forest, newdata = Dn_2)
cm = table(predictions,Dn_2$y)
classification_err <- 1 - sum(diag(cm)) / sum(cm)
classification_err
CM
cm
set.seed(123)
N <- nrow(train)
n1 <- 401
idx <- sample(1:N, n1, replace=F)
Dn_1 <- train_new[idx, ]
Dn_2 <- train_new[-idx, ]
modello_forest <- randomForest(factor(y) ~ . -id, data = Dn_1, importance = TRUE)
predictions <- predict(modello_forest, newdata = Dn_2)
cm = table(predictions,Dn_2$y)
classification_err <- 1 - sum(diag(cm)) / sum(cm)
classification_err
Dn_1$y <- factor(Dn_1$y)
model_tune <- train(y ~ . - id,
data = Dn_1,
method = "rf",
preProc = "scale",
tuneLength = 5
)
library(caret)
library(caret)
Dn_1$y <- factor(Dn_1$y)
model_tune <- train(y ~ . - id,
data = Dn_1,
method = "rf",
preProc = "scale",
tuneLength = 5
)
preds <- predict(model_tune, newdata = Dn_2)
preds
confusionMatrix(data = preds, factor(Dn_2$y))
ctrl <- trainControl(method = "repeatedcv", number = 10, repeats = 2, search = "random")
model_tune_xgb <- train(y ~ . - id,
data = Dn_1,
method = "xgbTree",
trControl = ctrl
)
preds <- predict(model_tune_xgb, newdata = Dn_2)
preds
confusionMatrix(data = preds, factor(Dn_2$y))
preds <- predict(model_tune_xgb, newdata = Dn_1)
preds
confusionMatrix(data = preds, factor(Dn_2$y))
confusionMatrix(data = preds, factor(Dn_1$y))
preds <- predict(model_tune_xgb, newdata = Dn_2)
preds
confusionMatrix(data = preds, factor(Dn_2$y))
cor(Dn_1)
cor(as.numeric(Dn_1))
cor(as.numeric(as.matrix(Dn_1)))
cor(as.numeric(as.matrix(Dn_1[,-c(1:4)])))
as.matrix(Dn_1[,-c(1:4)])
cor(as.matrix(Dn_1[,-c(1:4)]))
m = cor(as.matrix(Dn_1[,-c(1:4)]))
View(m)
install.packages("keras")
install.packages("tensorflow")
library("tensorflow")
library("keras")
model_nn <- keras_model_sequential()
Y
Dn_1
model_nn <- keras_model_sequential()
model %>%
layer_lstm(units = 64, input_shape = c(1, 236)) %>%
layer_dense(units = 2, activation = "sigmoid")
model_nn <- keras_model_sequential()
model_nn <- keras_model_sequential()
model_nn <- keras_model_sequential()
tensorflow
library("keras")
library("tensorflow")
model_nn <- keras_model_sequential()
modello_xgboost <- xgboost(data = as.matrix(Dn_1[, -y]),
label = Dn_1[, y],
nrounds = 100)
library(xgboost)
modello_xgboost <- xgboost(data = as.matrix(Dn_1[, -y]),
label = Dn_1[, y],
nrounds = 100)
modello_xgboost <- xgboost(data = as.matrix(Dn_1[, -4]),
label = Dn_1[, 4],
nrounds = 100)
pred <- predict(modello_xgboost, newdata = as.matrix(test_new))
pred <- predict(modello_xgboost, newdata = as.matrix(Dn_2[-4]))
pred <- predict(modello_xgboost, newdata = as.matrix(Dn_2[-4]), type = "response")
pred
View(Dn_2)
Dn_1[, 4]
pred <- predict(modello_xgboost, newdata = as.matrix(Dn_2[-4]), type = "prob")
pred
preds <- predict(modello_xgboost, newdata = as.matrix(Dn_2[-4]), type = "prob")
model_nn <- keras_model_sequential()
library("keras")
library("tensorflow")
model_nn <- keras_model_sequential()
confusionMatrix(preds, factor(Dn_2$y))
preds <- predict(modello_xgboost, newdata = as.matrix(Dn_2[-4]), type = "response")
modello_xgboost <- xgboost(data = as.matrix(Dn_1[, -4]),
label = Dn_1[, 4],
nrounds = 100)
preds <- predict(modello_xgboost, newdata = as.matrix(Dn_2[-4]), type = "response")
modello_xgboost <- xgboost(data = as.matrix(Dn_1[, -4]),
label = Dn_1[, 4],
nrounds = 100, objective = "binary:logistic")
modello_xgboost <- xgboost(data = as.matrix(Dn_1[, -4]),
label = Dn_1[, 4],
nrounds = 100, objective = "binary:logistic")
modello_xgboost <- xgboost(data = as.matrix(Dn_1[, -4]),
label = factor(Dn_1[, 4]),
nrounds = 100, objective = "binary:logistic")
modello_xgboost <- xgboost(data = as.matrix(Dn_1[, -4]),
label = factor(Dn_1[, 4]),
nrounds = 100, objective = "binary:logistic")
factor(Dn_1[, 4])
data("agaricus.train")
View(agaricus.train)
View(agaricus.train$label
modello_xgboost <- xgboost(data = as.matrix(Dn_1[, -4]),
label = factor(Dn_1[, 4]),
nrounds = 100, objective = "binary:logistic")
head(Dn_1)
X_train <- as.matrix(Dn_1[,-4])
y_train <- Dn_1$y
modello_xgboost <- xgboost(data = X_train),
modello_xgboost <- xgboost(data = X_train,
label = y,
nrounds = 100)
modello_xgboost <- xgboost(data = X_train,
label = y_train,
nrounds = 100)
X_test <- as.matrix(Dn_2[,-4])
preds <- predict(modello_xgboost, X_test))
preds <- predict(modello_xgboost, X_test)
preds = round(pred)
preds
y_train
rm(y_train)
y_train <- Dn_1$y
modello_xgboost <- xgboost(data = X_train,
label = y_train,
nrounds = 100, objective = "binary:logistic")
levels(y_train)= c("0","1")
modello_xgboost <- xgboost(data = X_train,
label = y_train,
nrounds = 100, objective = "binary:logistic")
levels(y_train)= c("1","2")
y_train
levels(y_train)= c("0","1")
modello_xgboost <- xgboost(data = X_train,
label = y_train,
nrounds = 100, objective = "binary:logistic")
modello_xgboost <- xgboost(data = X_train,
label = y_train,
nrounds = 100, objective = "binary:logistic")
modello_xgboost <- xgboost(data = X_train,
label = y_train,
nrounds = 100)
preds <- predict(modello_xgboost, X_test)
range(preds)
preds = ifelse(preds >=1.5,1,0)
table(preds)
confusionMatrix(preds, factor(Dn_2$y))
Dn2$y
Dn_2$y
table(Dn_2$y)
confusionMatrix(preds, Dn_2$y)
preds
confusionMatrix(factor(preds), Dn_2$y)
confusionMatrix(factor(preds), factor(Dn_2$y))
preds = ifelse(preds >=1.4,1,0)
table(preds)
confusionMatrix(factor(preds), factor(Dn_2$y))
preds = ifelse(preds >=1.6,1,0)
table(preds)
confusionMatrix(factor(preds), factor(Dn_2$y))
table(Dn_2$y)
preds = ifelse(preds >=1.5,1,0)
table(preds)
confusionMatrix(factor(preds), factor(Dn_2$y))
preds <- predict(modello_xgboost, X_test)
preds = ifelse(preds >=1.5,1,0)
confusionMatrix(factor(preds), factor(Dn_2$y))
prev = predict(modello_xgboost, test_new)
prev = predict(modello_xgboost, as.matrix(test_new))
View(test_new)
View(X_test)
X_valid <- as.matrix(test_new)
prev = predict(modello_xgboost, X_valid)
View(X_valid)
View(X_test)
X_valid <- as.matrix(test_new)
modello_xgboost <- xgboost(data = X_train,
label = y_train,
nrounds = 100)
X_valid <- as.matrix(test_new)
prev = predict(modello_xgboost, X_valid)
View(X_valid)
View(X_test)
colnames(X_valid) <- colnames(Dn_1[, -4])
prev = predict(modello_xgboost, X_valid)
range(prev)
prev = ifelse(preds >=1.5,1,0)
table(prev)
prev = ifelse(prev >=1.5,1,0)
table(prev)
prev = predict(modello_xgboost, X_valid)
prev = ifelse(prev >=1.5,1,0)
table(prev)
prev = ifelse(prev >=1.3,1,0)
table(prev)
prev = predict(modello_xgboost, X_valid)
prev = ifelse(prev >=1.3,1,0)
table(prev)
prev = predict(modello_xgboost, X_valid)
mean(prev)
median(prev)
prev = ifelse(prev >=1.28,1,0)
table(prev)
y_test = data.frame(test_new$id,prev)
View(y_test)
y_test = data.frame(id = test_new$id,prev)
write.csv(y_test, file = "prova.csv")
write.csv(y_test, file = "prova.csv", row.names = F)
y_test = data.frame(id = test_new$id,target = prev)
write.csv(y_test, file = "prova.csv", row.names = F)
View(y_test)
View(y_test)
View(test_new)
View(test)
y_test
levels(y_test)
levels(factor(y_test))
factor(y_test$target)
levels(y_test$target)
levels(factor(y_test$target))
y_test = data.frame(id = test_new$id,target = factor(prev))
levels(y_test$target)
write.csv(y_test, file = "prova.csv", row.names = F)
write.csv(y_test, file = "prova.csv", row.names = F)
View(train)
library(neuralnet)
install.packages("neuralnet")
model_neuralnet <- neuralnet(formula = y_train ~ X_train,
data = tuoi_dati_di_addestramento)
library(neuralnet)
model_neuralnet <- neuralnet(formula = y_train ~ X_train,
data = tuoi_dati_di_addestramento)
model_neuralnet <- neuralnet(formula = y_train ~ X_train)
model_neuralnet <- neuralnet(formula = y_train ~ X_train, data = X_train)
model_neuralnet <- neuralnet(formula = y ~ X_train, data = Dn_1)
View(Dn_1)
model_neuralnet <- neuralnet(formula = y ~ Dn_1[,-y], data = Dn_1)
model_neuralnet <- neuralnet(formula = y ~ Dn_1[,-4], data = Dn_1)
model_neuralnet <- neuralnet(formula = y ~ Dn_1[,-4], data = Dn_1)
model_neuralnet <- neuralnet(formula = y ~ . -id, data = Dn_1)
training <- train(modello_neuralnet)
training <- train(model_neuralnet)
print(model_neuralnet)
previsione <- compute(modello_neuralnet, Dn_2)
previsione <- compute(model_neuralnet, Dn_2)
View(previsione)
View(previsione)
previsione$net.result
# Estrai la colonna con il valore più grande
colonna_max <- apply(previsione$net.result, 1, which.max)
# Assegna etichette binarie 0 e 1
etichette <- ifelse(colonna_max == 1, 0, 1)
confusionMatrix(etichette, factor(Dn_2$y))
confusionMatrix(factor(etichette), factor(Dn_2$y))
model_neuralnet <- neuralnet(formula = y ~ . -id, data = Dn_1, threshold = 0.5)
previsione <- compute(model_neuralnet, Dn_2)
previsione$net.result
# Estrai la colonna con il valore più grande
colonna_max <- apply(previsione$net.result, 1, which.max)
# Assegna etichette binarie 0 e 1
etichette <- ifelse(colonna_max == 1, 0, 1)
confusionMatrix(factor(etichette), factor(Dn_2$y))
model_neuralnet <- neuralnet(formula = y ~ . -id, data = Dn_1, threshold = 0.5, rep = 5)
previsione <- compute(model_neuralnet, Dn_2)
previsione$net.result
# Estrai la colonna con il valore più grande
colonna_max <- apply(previsione$net.result, 1, which.max)
# Assegna etichette binarie 0 e 1
etichette <- ifelse(colonna_max == 1, 0, 1)
confusionMatrix(factor(etichette), factor(Dn_2$y))
model_neuralnet <- neuralnet(formula = y ~ . -id, data = Dn_1, threshold = 0.5, rep = 10)
model_neuralnet <- neuralnet(formula = y ~ . -id, data = Dn_1, threshold = 0.5, rep = 10)
previsione <- compute(model_neuralnet, Dn_2)
previsione$net.result
previsione$net.result
# Estrai la colonna con il valore più grande
colonna_max <- apply(previsione$net.result, 1, which.max)
# Assegna etichette binarie 0 e 1
etichette <- ifelse(colonna_max == 1, 0, 1)
previsione$net.result
# Estrai la colonna con il valore più grande
colonna_max <- apply(previsione$net.result, 1, which.max)
# Assegna etichette binarie 0 e 1
etichette <- ifelse(colonna_max == 1, 0, 1)
confusionMatrix(factor(etichette), factor(Dn_2$y))
model_neuralnet <- neuralnet(formula = y ~ . -id, data = Dn_1, threshold = 0.3, rep = 10)
model_neuralnet <- neuralnet(formula = y ~ . -id, data = Dn_1, threshold = 0.3, rep = 10)
previsione <- compute(model_neuralnet, Dn_2)
previsione <- compute(model_neuralnet, Dn_2)
previsione$net.result
# Estrai la colonna con il valore più grande
colonna_max <- apply(previsione$net.result, 1, which.max)
previsione <- compute(model_neuralnet, Dn_2)
previsione$net.result
# Estrai la colonna con il valore più grande
colonna_max <- apply(previsione$net.result, 1, which.max)
# Assegna etichette binarie 0 e 1
etichette <- ifelse(colonna_max == 1, 0, 1)
confusionMatrix(factor(etichette), factor(Dn_2$y))
model_neuralnet <- neuralnet(formula = y ~ . -id, data = Dn_1, threshold = 0.3, rep = 10, hidden = 3)
model_neuralnet <- neuralnet(formula = y ~ . -id, data = Dn_1, threshold = 0.3, rep = 10, hidden = 3)
previsione <- compute(model_neuralnet, Dn_2)
previsione <- compute(model_neuralnet, Dn_2)
previsione$net.result
model_neuralnet <- neuralnet(formula = y ~ . -id, data = Dn_1, threshold = 0.3, rep = 10, hidden = 3)
previsione <- compute(model_neuralnet, Dn_2)
previsione$net.result
# Estrai la colonna con il valore più grande
colonna_max <- apply(previsione$net.result, 1, which.max)
# Estrai la colonna con il valore più grande
colonna_max <- apply(previsione$net.result, 1, which.max)
# Assegna etichette binarie 0 e 1
etichette <- ifelse(colonna_max == 1, 0, 1)
confusionMatrix(factor(etichette), factor(Dn_2$y))
model_neuralnet <- neuralnet(formula = y ~ . -id, data = Dn_1, threshold = 0.5, rep = 10, hidden = 3)
model_neuralnet <- neuralnet(formula = y ~ . -id, data = Dn_1, threshold = 0.5, rep = 10, hidden = 3)
previsione <- compute(model_neuralnet, Dn_2)
previsione$net.result
# Estrai la colonna con il valore più grande
colonna_max <- apply(previsione$net.result, 1, which.max)
# Estrai la colonna con il valore più grande
colonna_max <- apply(previsione$net.result, 1, which.max)
# Assegna etichette binarie 0 e 1
etichette <- ifelse(colonna_max == 1, 0, 1)
confusionMatrix(factor(etichette), factor(Dn_2$y))
previsione <- compute(model_neuralnet, Dn_1)
previsione$net.result
# Estrai la colonna con il valore più grande
colonna_max <- apply(previsione$net.result, 1, which.max)
# Assegna etichette binarie 0 e 1
etichette <- ifelse(colonna_max == 1, 0, 1)
confusionMatrix(factor(etichette), factor(Dn_2$y))
confusionMatrix(factor(etichette), factor(Dn_1$y))
# Esempio di regressione logistica L1 (Lasso)
fit <- glmnet(X_train, y_train, family = "binomial", alpha = 1)
library(glmnet)
# Esempio di regressione logistica L1 (Lasso)
fit <- glmnet(X_train, y_train, family = "binomial", alpha = 1)
# Esempio di regressione logistica L1 (Lasso)
fit_L1 <- glmnet(X_train, y_train, family = "binomial", alpha = 1)
# Esempio di regressione logistica L1 (Lasso)
fit_L1 <- glmnet(X_train, y_train, family = "binomial", alpha = 1)
# Esempio di regressione logistica L2 (Ridge)
fit_L2 <- glmnet(x, y, family = "binomial", alpha = 0)
plot(fit_L1)
plot(fit_L1)
# Esempio di regressione logistica L2 (Ridge)
fit_L2 <- glmnet(X_train, y_train, family = "binomial", alpha = 0)
plot(fit_L2)
cv.fit <- cv.glmnet(X_train, y_train, family = "binomial", alpha = 1)
best_coef <- coef(cv.fit, s = "lambda.min")
View(best_coef)
predictions <- predict(fit_L1, newx = X_test, type = "response")
View(predictions)
predictions <- predict(fit_L1, newx = Dn_2, type = "response")
View(predictions)
# Esempio di regressione logistica L1 (Lasso)
fit_L1 <- glmnet(X_train, y_train, family = "binomial", alpha = 1)
predictions <- predict(fit_L1, newx = X_test, type = "response")
View(X_train)
predictions_glm <- predict(fit_L1, newx = X_test, type = "response")
predictions_glm <- predict(fit_L1, newx = X_test, type = "class")
predictions_glm <- predict(fit_L1, newx = test_new, type = "class")
predictions_glm <- predict(fit_L1, newx = as.matrix(test_new), type = "class")
X_test
predictions_glm <- predict(fit_L1, newx = X_test, type = "response")
predictions_glm <- predict(fit_L1, newx = X_test)
View(predictions_glm)
predictions <- predict(fit_L1, newx = X_test, type = "response")
# Esempio di regressione logistica L2 (Ridge)
fit_L2 <- glmnet(X_train, y_train, family = "binomial", alpha = 0)
cv.fit <- cv.glmnet(X_train, y_train, family = "binomial", alpha = 0)
predictions <- predict(fit_L1, newx = X_test, type = "response")
predictions <- predict(fit_L2, newx = X_test, type = "response")
View(predictions)
predictions <- predict(fit_L2, newx = X_test, type = "response", s = 0.001)
View(predictions)
predictions <- predict(fit_L1, newx = X_test, type = "response", s = 0.001)
# Esempio di regressione logistica L1 (Lasso)
fit_L1 <- glmnet(X_train, y_train, family = "binomial", alpha = 1, relax = T, path = T)
predictions <- predict(fit_L1, newx = X_test, type = "response", s = 0.001)
